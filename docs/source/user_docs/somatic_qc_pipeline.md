# Nextflow: Somatic variant calling pipeline

Somatic variant calling and post-processing for DERMATLAS can be run mostly with a single nextflow pipeline in a largely "set-and-forget" manner to reproduce the manual steps detailed in [DERMATLAS - Post-processing CaVEMan and Pindel calls]()

This document contains an overview of how to configure and run the pipeline; for a more detailed explanation of the pipeline inputs and requirements for running can be found within the project [README](https://gitlab.internal.sanger.ac.uk/DERMATLAS/analysis-methods/dermatlas_somatic_qc_nf)

## Workflow Overview

1. **Generating pipeline inputs for Dermatlas studies** 
2. **Generating the cohort config file**
3. **Running the pipeline**
4. **Make a release folder**


### 1. Generating pipeline inputs for Dermatlas studies

The study-specific inputs required to run the copy number calling pipeline are: the sample vcfs for a study's matched tumour-normal pairs; sets of the sample groupings; and the study metadata sheet. See [dematlas analysis setup]() for instructions on how to prepare these.

Somatic QC is run on several cohort sample lists: matched tumours only, one tumour per patient, all independent tumours, etc.

### 2. Generating the cohort config file

The nextflow pipeline’s config file encodes all the options and inputs we might want to pass to the pipeline. For newer versions of Dermanager (dermanager >= 0.4.3) this will be autogenerated for you and populated in your project directory in `commands/somatic_variants.config`. A wrapper script for launching the pipeline should also be created in `commands/run_somatic_variants.sh`

The defaults provided should be suitable for running out of the box but for some pipeline runs there are a handful of parameters that you might consider changing:


- The `cohort prefix` (which will be used in the labelling of output files)
- The path to the `caveman_vcfs`  and the path to the `pindel_vcfs`
- The paths to write the outputs of caveman and pindel filtering to (`caveman_outdir` and `pindel_outdir`; in Dermatlas this is normally the same directory that `caveman_vcfs` and `pindel_vcfs` reside in)
- The output directory to publish somatic variant QC results into
- The completed biosample manifest for the cohort
- The `one_per_patient`, independent tumours and all-sample sample lists generated in stage 2

There is an extensive set of other parameters are specified, but won't normally need changing. These are mostly paths to reference files, which don't change. For convenience of maintaining the pipeline in a way that in can be run on or off farm22, most of the reference files are stored in

/lustre/scratch124/casm/team113/secure-lustre/resources/dermatlas  
These are direct copies of the resources directories for legacy dermatlas PUS

**Example file:**

```
  

```

**somatic\_variant.config**

```java
params {
    cohort_prefix = "${STUDY}_${PROJECT}_${COHORT}"
    caveman_vcfs = "${PROJECT_DIR}/analysis/caveman_files/**.smartphase.vep.vcf.gz"
    caveman_outdir = "${PROJECT_DIR}/analysis/caveman_files"
    pindel_vcfs = "${PROJECT_DIR}/analysis/pindel_files/**.pindel.vep.vcf.gz"
    pindel_outdir = "${PROJECT_DIR}/analysis/pindel_files"
    outdir = "${PROJECT_DIR}/analysis/variants_combined"
    release_version = "version1"
    metadata_manifest = "${PROJECT_DIR}/metadata/${STUDY}-biosample-manifest-completed.tsv"
    all_samples = "${PROJECT_DIR}/metadata/${STUDY}_${PROJECT}-analysed_all_tum.txt"
    one_per_patient = "${PROJECT_DIR}/metadata/${STUDY}_${PROJECT}-one_tumour_per_patient_all_tum.txt"
    independent = "${PROJECT_DIR}/metadata/${STUDY}_${PROJECT}-independent_tumours_all.tsv"
 
}
```

**Launching the nextflow pipeline**

Once you have your inputs and are authenticated you can prepare to launch the pipeline by modifying and saving this wrapper script in you project directory. You will need to update the desitination of the params file and your desired log file locations. 

In this script the "`-r"`  option specifies which version of the pipeline you'd like to run. Normally you should select the latest version.

**Example file:**

**run\_somatic\_calling.sh**

```java
#!/bin/bash
#BSUB -q oversubscribed
#BSUB -G team113-grp
#BSUB -R "select[mem>8000] rusage[mem=8000] span[hosts=1]"
#BSUB -M 8000
#BSUB -oo analysis/logs/somatic_variants_pipeline_%J.o
#BSUB -eo analysis/logs/somatic_variants_pipeline_%J.e

set -euo pipefail

source source_me.sh 

export COHORT="DEMO"
export REVISION="0.6.3"

# Load module dependencies
module load nextflow-23.10.0
module load /software/modules/ISG/singularity/3.11.4
 
# Create a nextflow job that will spawn other jobs
nextflow run 'https://github.com/team113sanger/dermatlas_somatic_qc_nf' \
-resume \
-r ${REVISION} \
-c commands/somatic_variants.config \
-profile farm22
```

If you called the script `run_somatic_calling.sh` then you'll be able to submit 

```java
bsub < run_somatic_calling.sh
```

The bsub magic at the start of the wrapper script will send a nextflow "master job", which looks after all other jobs to the oversubscribed queue (where it can live in peace running for a long period without fear of termination). Nextflow will shortly start submitting jobs on your behalf to the relevant queues

### Troubleshooting problem nextflow runs:

### There are several reasons the gemline pipeline might fail including bugs in the pipeline; issues with LSF; or misconfiguration.  In most cases (especially when you suspect a farm/ LSF failure), simply re-submitting the pipeline with

```java
bsub < run_somatic_calling.sh
```

will trigger the nextflow `-resume` directive and the pipeline will pick up where it left off.

It is often worth taking a glance at the pipeline logs (<YOUR\_PROJECT\_DIR>/analysis/logs/gemline\_calling\_%J.o) to follow and see what's going on, especially if things have failed/

When jobs fail, nextflow will provide the path to the directory a failed job was run in. I'd recommend inspecting the files in here with `ls -la` and printing some of the log files for the job with

```java
cat .command.err
cat .command.out
cat .command.sh

```

> [!IMPORTANT]
> Multiple runs
>
> Nextflow is able to keep track of past runs by creating a .nextflow directory in the current location and stores intermediate files in a work. If you want to run the same pipeline but on different cohorts (e.g. hidradenomas and hidradenocarcionmas) in parallel, please ensure that you launch each instance of the pipeline in a seperate directory - otherwise nextflow can't keep track of what is going on an report errors about "nextflow lock files "

**Make a release folder**

"Creating a release" allows you to copy out the key results from Somatic variant QC into a seperate folder. This can be performed in exactly the same way as detailed in [DERMATLAS - Post-processing CaVEMan and Pindel calls](/spaces/CAS/pages/116131145/DERMATLAS+-+Post-processing+CaVEMan+and+Pindel+calls)  

```java
export PROJECT_DIR="/lustre/scratch125/casm/team113da/projects/dermatlas_pu11_project_dir/7651_3442_DERMATLAS_Superficial_acral_fibromyxoma_WES"
export STUDY=7651
export PROJECT=3442
export COHORT="Superficial_acral_fibromyxoma"
PREFIX="${STUDY}_${PROJECT}"
  
cd $PROJECT_DIR/analysis/variants_combined
i=1
mkdir release_v${i}
source ${PROJECT_DIR}/scripts/maf/source_me.sh
bash ${PROJECT_DIR}/scripts/maf/make_variant_release.sh \
$PROJECT_DIR ${COHORT} version${i} release_v${i} > release_v${i}/files.log




```
